{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Data Summary-----\n",
      "Number of Columns: 4\n",
      "Number of Valid Features: 3\n",
      "Number of Entries: 245057\n",
      "NaN Values Found: None\n",
      "Empty Values Found: None\n",
      "Corellated Found: None\n",
      "\n",
      "-----General Dataframe Information-----\n",
      "\n",
      "                 Red          Green           Blue          Class\n",
      "count  245057.000000  245057.000000  245057.000000  245057.000000\n",
      "mean      125.065446     132.507327     123.177151       1.792461\n",
      "std        62.255653      59.941197      72.562165       0.405546\n",
      "min         0.000000       0.000000       0.000000       1.000000\n",
      "25%        68.000000      87.000000      70.000000       2.000000\n",
      "50%       139.000000     153.000000     128.000000       2.000000\n",
      "75%       176.000000     177.000000     164.000000       2.000000\n",
      "max       255.000000     255.000000     255.000000       2.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import seed\n",
    "from random import random\n",
    "import math\n",
    "import sys\n",
    "\n",
    "df = pd.read_table('classification_data.tsv')\n",
    "\n",
    "#Converting string date time to datetime obj\n",
    "#Testing for nan or empty values\n",
    "nan = np.array(np.where(pd.isnull(df)))\n",
    "empty = np.array(np.where(df.applymap(lambda x: x == '')))\n",
    "\n",
    "corr = df.corr(method='pearson')\n",
    "indices = np.where(corr > 0.90)\n",
    "indices = [(corr.index[x], corr.columns[y]) for x, y in zip(*indices) if x != y and x < y]\n",
    "\n",
    "#Number of features = number of columns - the target class field\n",
    "features = len(df.columns) - 1\n",
    "\n",
    "df['Class'] = df['Class'].apply(lambda val: int(val))\n",
    "\n",
    "print(\"-----Data Summary-----\")\n",
    "\n",
    "print(\"Number of Columns: \" + str(len(df.columns)))\n",
    "print(\"Number of Valid Features: \" + str(features))\n",
    "print(\"Number of Entries: \" + str(df.shape[0]))\n",
    "\n",
    "if(nan):\n",
    "    print(\"NaN Values Found: \" + str(nan))\n",
    "else:\n",
    "    print(\"NaN Values Found: None\")\n",
    "    \n",
    "if(empty):\n",
    "    print(\"Empty Values Found: \" + str(empty))\n",
    "else:\n",
    "    print(\"Empty Values Found: None\")\n",
    "    \n",
    "if(len(indices) > 0):\n",
    "    print(\"Correlated Values Found: \" + str(indices))\n",
    "else:\n",
    "    print(\"Corellated Found: None\")\n",
    "    \n",
    "print(\"\\n-----General Dataframe Information-----\\n\")\n",
    "print(df.describe())\n",
    "\n",
    "def Plot(data, plot, columns, col_x,col_y):\n",
    "    x = columns[col_x]\n",
    "    y = columns[col_y]\n",
    "    plot.set_xlabel(x)\n",
    "    plot.set_ylabel(y)\n",
    "    plot.set_title(x + \" vs \" + y)\n",
    "    \n",
    "    plot.scatter(data[x].values,data[y].values)\n",
    "\n",
    "def Cross_Plot(data):\n",
    "    cols = data.columns\n",
    "    num_cols = features\n",
    "    plt.figure(figsize=(200,150),facecolor='white')\n",
    "    for col in range(0,num_cols):\n",
    "            for cross_col in range(0,num_cols):\n",
    "                if col != cross_col:\n",
    "                    ax = plt.subplot2grid((num_cols, num_cols), (col, cross_col))\n",
    "                    Plot(data, ax,cols,col, cross_col)\n",
    "    plt.show()\n",
    "\n",
    "#Running this takes some time, but a version of the output has been included in the mark down above\n",
    "#Cross_Plot(df.drop(['Class'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def Get_KFolds(data, y_label, num_folds):\n",
    "    #Creates 5 folds from the train/test set each with a separate training and test set\n",
    "    folds = []\n",
    "    kf = KFold(n_splits = num_folds)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        training = []\n",
    "        test = []\n",
    "        \n",
    "        train_x = data.drop(y_label, axis=1).values\n",
    "        train_y = data[y_label].values\n",
    "        \n",
    "        #Creates a training set within the fold\n",
    "        x = []\n",
    "        y = []\n",
    "        id = []\n",
    "        \n",
    "        for index in train_index:\n",
    "            x.append(train_x[index])\n",
    "            y.append(train_y[index])\n",
    "        training = [x,y]\n",
    "        \n",
    "        #Creates a test set within the fold\n",
    "        x = []\n",
    "        y = []\n",
    "        id = []\n",
    "        for index in test_index:\n",
    "            x.append(train_x[index])\n",
    "            y.append(train_y[index])\n",
    "        test = [x,y]\n",
    "\n",
    "        folds.append([training,test])\n",
    "    \n",
    "    return folds\n",
    "\n",
    "seed(1)\n",
    "\n",
    "train_df,test_df = train_test_split(df,test_size=0.2,random_state=42)\n",
    "train_df = train_df[:100000]\n",
    "\n",
    "num_folds = 5\n",
    "folds = Get_KFolds(train_df, 'Class', num_folds);\n",
    "train = [train_df.drop(['Class'], axis = 1).values, train_df['Class'].values]\n",
    "test = [test_df.drop(['Class'], axis = 1).values, test_df['Class'].values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Grabbed this code from sklearn reference \n",
    "#http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "log_cv = GridSearchCV(estimator = linear_model.LogisticRegression(solver='sag'), cv=5, param_grid = {'max_iter':[4000],'C':[0.001,0.01,0.1,1,10,100,1000]}, n_jobs=-1)\n",
    "log_cv.fit(train[0][:20000],train[1][:20000])\n",
    "log_params = log_cv.best_params_\n",
    "\n",
    "log = linear_model.LogisticRegression(solver='sag', max_iter = [4000])\n",
    "log.set_params(**log_params)\n",
    "\n",
    "print(\"Log Hyperparameters: {}\".format(log_params))\n",
    "sys.stdout.flush()\n",
    "\n",
    "p_grid = [{'kernel':['linear'],'C':[0.1, 0.5, 1, 2, 5]}, \n",
    "         {'kernel':['poly'],'degree':[2,3],'C':[0.1, 0.5, 1, 2, 5, 1000]},\n",
    "         {'kernel':['rbf'],'gamma':[0.1, 0.5, 1, 2, 5],'C':[0.1, 0.5, 1, 2, 5, 1000]}]\n",
    "\n",
    "svm_cv = GridSearchCV(estimator = svm.SVC(), param_grid= p_grid, n_jobs=-1)\n",
    "svm_cv.fit(train[0][:10000],train[1][:10000])\n",
    "svm_params = svm_cv.best_params_\n",
    "\n",
    "print(\"SVM Hyperparameters: {}\".format(svm_params))\n",
    "sys.stdout.flush()\n",
    "\n",
    "svm_m = svm.SVC()\n",
    "svm_m.set_params(**svm_params)\n",
    "\n",
    "svm_avg = 0\n",
    "log_avg = 0\n",
    "\n",
    "for i in range(len(folds)):\n",
    "    print('\\n-----Fold #{}-----\\n'.format(i + 1))\n",
    "    x = folds[i][0][0]\n",
    "    y = np.array(folds[i][0][1]).flatten()\n",
    "    \n",
    "    log.fit(x,y)\n",
    "    log_score = log.score(folds[i][1][0],folds[i][1][1])\n",
    "    log_avg += log_score / num_folds\n",
    "    \n",
    "    svm_m.fit(x,y)\n",
    "    svm_score = svm_m.score(folds[i][1][0],folds[i][1][1])\n",
    "    svm_avg += svm_score / num_folds\n",
    "    \n",
    "    print(\"\\tLog Score: {}\".format(log_score))\n",
    "    print(\"\\tSVM Score: {}\".format(svm_score))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "print(\"\\n-----Training Average-----\\n\")\n",
    "print(\"\\tLog Score: {}\".format(log_avg))\n",
    "print(\"\\tSVM Score: {}\".format(svm_avg))\n",
    "sys.stdout.flush()\n",
    "\n",
    "print(\"\\n-----Testing-----\\n\")\n",
    "score = log.score(test[0],test[1])\n",
    "predictions = log.predict(test[0])\n",
    "log_matrix = confusion_matrix(test[1],predictions)\n",
    "print(\"\\tLog Score: {}\".format(score))\n",
    "\n",
    "score = svm_m.score(test[0],test[1])\n",
    "predictions = svm_m.predict(test[0])\n",
    "svm_matrix = confusion_matrix(test[1],predictions)\n",
    "print(\"\\tSVM Score: {}\".format(score))\n",
    "    \n",
    "plot_confusion_matrix(log_matrix, classes=['1','2'],\n",
    "                      title='Log Confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plot_confusion_matrix(svm_matrix, classes=['1','2'],\n",
    "                      title='SVM Confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
